# -*- coding: utf-8 -*-
"""Dog Breed Classification.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Pc4vYJeaf7-rXjyPoAhXDxVB6B_O1M0M

The Oxford - IIIT Pet Dataset

The Oxford-IIIT Pet Dataset is a collection of pet images for computer vision tasks. It has 37 categories (like dog breeds) with around 200 images each. The images have variations in size, pose, and lighting, making it more realistic. It's great for training models to classify pet breeds or even segment the image (separate pet from background).

This dataset is of size 2GB, to use, upload it first to drive and then use.
Download link for dataset: https://www.robots.ox.ac.uk/~vgg/data/pets/
"""

# This code requires TensorFlow and Keras to be installed

from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense

# Define data paths (replace with your actual data paths)
train_data_dir = 'path/to/your/train/data'  # Replace with your training data path in Google Drive
validation_data_dir = 'path/to/your/validation/data'  # Replace with your validation data path in Google Drive

# Set image dimensions (adjust if needed)
img_width, img_height = 150, 150

train_data_dir = '/content/drive/MyDrive/oxford-pets/train'
validation_data_dir = '/content/drive/MyDrive/oxford-pets/validation'
img_width, img_height = 150, 150

# Define batch size (adjust based on GPU memory)
batch_size = 32

# Data augmentation for training data (improves model robustness)
train_datagen = ImageDataGenerator(rescale=1./255, shear_range=0.2, zoom_range=0.2, horizontal_flip=True)

# No data augmentation for validation data (evaluates model on raw images)
validation_datagen = ImageDataGenerator(rescale=1./255)

# Define data generators for training and validation
train_generator = train_datagen.flow_from_directory(
    train_data_dir,
    target_size=(img_width, img_height),
    batch_size=batch_size,
    class_mode='categorical'
)

validation_generator = validation_datagen.flow_from_directory(
    validation_data_dir,
    target_size=(img_width, img_height),
    batch_size=batch_size,
    class_mode='categorical'
)

# Define a simple CNN model
model = Sequential([
  # First convolutional layer with 32 filters, ReLU activation
  Conv2D(32, (3, 3), activation='relu', input_shape=(img_width, img_height, 3)),
  # Max pooling for dimensionality reduction
  MaxPooling2D((2, 2)),
  # Second convolutional layer with 64 filters, ReLU activation
  Conv2D(64, (3, 3), activation='relu'),
  # Max pooling for dimensionality reduction
  MaxPooling2D((2, 2)),
  # Flatten layer to prepare for fully connected layers
  Flatten(),
  # Dense layer with 128 neurons, ReLU activation
  Dense(128, activation='relu'),
  # Output layer with number of dog breeds (softmax activation for probability distribution)
  Dense(len(train_generator.classes), activation='softmax')
])

# Compile the model (specifies loss function, optimizer, and metrics)
model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])

# Train the model (adjust epochs based on dataset size and validation performance)
model.fit(train_generator, epochs=10, validation_data=validation_generator)

# (Optional) Save the trained model for future use
#model.save('dog_breed_classifier.h5')

# (Optional) Evaluate the model performance on unseen validation data
#loss, accuracy = model.evaluate(validation_generator)
#print('Accuracy:', accuracy)